{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from dotenv import load_dotenv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Neural networks imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dotenv file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API credentials\n",
    "client_id = os.getenv(\"CLIENT_ID\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "\n",
    "# Authentication - without user\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>all_artists</th>\n",
       "      <th>popularity_artist</th>\n",
       "      <th>popularity_song</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7zgqtptZvhf8GEmdsM2vp2</td>\n",
       "      <td>...Ready For It?</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.779</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.454</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.453</td>\n",
       "      <td>160.000</td>\n",
       "      <td>208198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4Vxu50qVrQcycjRyJQaZLC</td>\n",
       "      <td>Life Changes</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.845</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.370</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.809</td>\n",
       "      <td>87.972</td>\n",
       "      <td>190227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6b8Be6ljOzmkOmFslEb23P</td>\n",
       "      <td>24K Magic</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.632</td>\n",
       "      <td>106.970</td>\n",
       "      <td>225983</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0afhq8XCExXpqazXczTSve</td>\n",
       "      <td>Galway Girl</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>91</td>\n",
       "      <td>77</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.876</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.374</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.781</td>\n",
       "      <td>99.943</td>\n",
       "      <td>170827</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1HNkqx9Ahdgi1Ixy2xkKkL</td>\n",
       "      <td>Photograph</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>91</td>\n",
       "      <td>83</td>\n",
       "      <td>2014-06-21</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.379</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60700</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.201</td>\n",
       "      <td>107.989</td>\n",
       "      <td>258987</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918</th>\n",
       "      <td>9918</td>\n",
       "      <td>4UFlPCB4THnQ9TlPHqIQow</td>\n",
       "      <td>Funeral For A Friend / Love Lies Bleeding</td>\n",
       "      <td>Elton John</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1973-10-05</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.761</td>\n",
       "      <td>9</td>\n",
       "      <td>-8.507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01980</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.193</td>\n",
       "      <td>138.712</td>\n",
       "      <td>666572</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>9919</td>\n",
       "      <td>5pSSEkT0963muzzIjsVkrs</td>\n",
       "      <td>Fool's Overture</td>\n",
       "      <td>Supertramp</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>1977-01-01</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.306</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.073</td>\n",
       "      <td>135.272</td>\n",
       "      <td>652560</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>9920</td>\n",
       "      <td>7gC6Rbllqf1yXNC02e5jz2</td>\n",
       "      <td>Heart of the Sunrise - 2003 Remaster</td>\n",
       "      <td>Yes</td>\n",
       "      <td>59</td>\n",
       "      <td>45</td>\n",
       "      <td>1971-11-26</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.507</td>\n",
       "      <td>1</td>\n",
       "      <td>-11.229</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01740</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.456</td>\n",
       "      <td>146.641</td>\n",
       "      <td>634440</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>9921</td>\n",
       "      <td>6Ff77WXC58MkhLE5A1qgY1</td>\n",
       "      <td>Venus And Mars / Rock Show / Jet - Live / Rema...</td>\n",
       "      <td>Wings</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1976-12-10</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.733</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.671</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08870</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.380</td>\n",
       "      <td>128.512</td>\n",
       "      <td>620747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>9922</td>\n",
       "      <td>1is5wwajEk2JW7Nsd63r3m</td>\n",
       "      <td>Mr. Brightside</td>\n",
       "      <td>The Killers</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2004-06-15</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.932</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.226</td>\n",
       "      <td>148.148</td>\n",
       "      <td>222107</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9923 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                      id  \\\n",
       "0              0  7zgqtptZvhf8GEmdsM2vp2   \n",
       "1              1  4Vxu50qVrQcycjRyJQaZLC   \n",
       "2              2  6b8Be6ljOzmkOmFslEb23P   \n",
       "3              3  0afhq8XCExXpqazXczTSve   \n",
       "4              4  1HNkqx9Ahdgi1Ixy2xkKkL   \n",
       "...          ...                     ...   \n",
       "9918        9918  4UFlPCB4THnQ9TlPHqIQow   \n",
       "9919        9919  5pSSEkT0963muzzIjsVkrs   \n",
       "9920        9920  7gC6Rbllqf1yXNC02e5jz2   \n",
       "9921        9921  6Ff77WXC58MkhLE5A1qgY1   \n",
       "9922        9922  1is5wwajEk2JW7Nsd63r3m   \n",
       "\n",
       "                                                  title   all_artists  \\\n",
       "0                                      ...Ready For It?  Taylor Swift   \n",
       "1                                          Life Changes  Thomas Rhett   \n",
       "2                                             24K Magic    Bruno Mars   \n",
       "3                                           Galway Girl    Ed Sheeran   \n",
       "4                                            Photograph    Ed Sheeran   \n",
       "...                                                 ...           ...   \n",
       "9918          Funeral For A Friend / Love Lies Bleeding    Elton John   \n",
       "9919                                    Fool's Overture    Supertramp   \n",
       "9920               Heart of the Sunrise - 2003 Remaster           Yes   \n",
       "9921  Venus And Mars / Rock Show / Jet - Live / Rema...         Wings   \n",
       "9922                                     Mr. Brightside   The Killers   \n",
       "\n",
       "      popularity_artist  popularity_song release_date  danceability  energy  \\\n",
       "0                    92                0   2017-09-03         0.615   0.779   \n",
       "1                    74               63   2017-09-08         0.687   0.845   \n",
       "2                    87               78   2016-11-17         0.818   0.803   \n",
       "3                    91               77   2017-03-03         0.624   0.876   \n",
       "4                    91               83   2014-06-21         0.614   0.379   \n",
       "...                 ...              ...          ...           ...     ...   \n",
       "9918                 82                0   1973-10-05         0.410   0.761   \n",
       "9919                 67               52   1977-01-01         0.406   0.306   \n",
       "9920                 59               45   1971-11-26         0.362   0.507   \n",
       "9921                 69                0   1976-12-10         0.331   0.733   \n",
       "9922                 76                0   2004-06-15         0.342   0.932   \n",
       "\n",
       "      key  loudness  mode  acousticness  instrumentalness  liveness  valence  \\\n",
       "0       2    -6.454     1       0.06650          0.000000    0.1550    0.453   \n",
       "1       7    -4.370     1       0.10000          0.000000    0.0452    0.809   \n",
       "2       1    -4.282     1       0.03400          0.000000    0.1530    0.632   \n",
       "3       9    -3.374     1       0.07350          0.000000    0.3270    0.781   \n",
       "4       4   -10.480     1       0.60700          0.000464    0.0986    0.201   \n",
       "...   ...       ...   ...           ...               ...       ...      ...   \n",
       "9918    9    -8.507     0       0.01980          0.084700    0.2470    0.193   \n",
       "9919    3   -10.482     1       0.31300          0.007900    0.0727    0.073   \n",
       "9920    1   -11.229     1       0.01740          0.216000    0.1130    0.456   \n",
       "9921    2    -8.671     1       0.08870          0.001740    0.9470    0.380   \n",
       "9922    1    -3.644     1       0.00106          0.000000    0.0938    0.226   \n",
       "\n",
       "        tempo  duration_ms  time_signature  \n",
       "0     160.000       208198               4  \n",
       "1      87.972       190227               4  \n",
       "2     106.970       225983               4  \n",
       "3      99.943       170827               4  \n",
       "4     107.989       258987               4  \n",
       "...       ...          ...             ...  \n",
       "9918  138.712       666572               4  \n",
       "9919  135.272       652560               4  \n",
       "9920  146.641       634440               3  \n",
       "9921  128.512       620747               4  \n",
       "9922  148.148       222107               4  \n",
       "\n",
       "[9923 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv('../Data/song_data(pop-artist).csv')\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the songs with 0 popularity\n",
    "df.drop(df[df['popularity_song'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing duration to minutes instead of milliseconds\n",
    "# df['duration_m'] = df['duration_ms']/60000\n",
    "# df = data.reindex(sorted(df.columns), axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this tell us about the songs?\n",
    "\n",
    "Going back to our hypothesis, predicting a hit song based on certain features. The above visualization highlight the the most relevant features based on popularity of the songs.\n",
    "Stand out features are:\n",
    "* Energy\n",
    "* Danceability\n",
    "* Loudness\n",
    "* Acousticness\n",
    "* Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>all_artists</th>\n",
       "      <th>popularity_artist</th>\n",
       "      <th>popularity_song</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Life Changes</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.845</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.370</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.809</td>\n",
       "      <td>87.972</td>\n",
       "      <td>190227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24K Magic</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.632</td>\n",
       "      <td>106.970</td>\n",
       "      <td>225983</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Galway Girl</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>91</td>\n",
       "      <td>77</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.876</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.374</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.781</td>\n",
       "      <td>99.943</td>\n",
       "      <td>170827</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Photograph</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>91</td>\n",
       "      <td>83</td>\n",
       "      <td>2014-06-21</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.379</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6070</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.201</td>\n",
       "      <td>107.989</td>\n",
       "      <td>258987</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Havana (feat. Young Thug)</td>\n",
       "      <td>Young Thug</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.517</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.323</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.418</td>\n",
       "      <td>104.992</td>\n",
       "      <td>216897</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title   all_artists  popularity_artist  \\\n",
       "1               Life Changes  Thomas Rhett                 74   \n",
       "2                  24K Magic    Bruno Mars                 87   \n",
       "3                Galway Girl    Ed Sheeran                 91   \n",
       "4                 Photograph    Ed Sheeran                 91   \n",
       "5  Havana (feat. Young Thug)    Young Thug                 83   \n",
       "\n",
       "   popularity_song release_date  danceability  energy  key  loudness  mode  \\\n",
       "1               63   2017-09-08         0.687   0.845    7    -4.370     1   \n",
       "2               78   2016-11-17         0.818   0.803    1    -4.282     1   \n",
       "3               77   2017-03-03         0.624   0.876    9    -3.374     1   \n",
       "4               83   2014-06-21         0.614   0.379    4   -10.480     1   \n",
       "5                1   2017-08-03         0.768   0.517    7    -4.323     0   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "1        0.1000          0.000000    0.0452    0.809   87.972       190227   \n",
       "2        0.0340          0.000000    0.1530    0.632  106.970       225983   \n",
       "3        0.0735          0.000000    0.3270    0.781   99.943       170827   \n",
       "4        0.6070          0.000464    0.0986    0.201  107.989       258987   \n",
       "5        0.1860          0.000038    0.1040    0.418  104.992       216897   \n",
       "\n",
       "   time_signature  \n",
       "1               4  \n",
       "2               4  \n",
       "3               4  \n",
       "4               4  \n",
       "5               4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Unecessary columns\n",
    "df_nn = df.drop(['Unnamed: 0','id'], axis = 1)\n",
    "df_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acousticness',\n",
       " 'danceability',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'mode',\n",
       " 'loudness',\n",
       " 'tempo',\n",
       " 'valence',\n",
       " 'popularity_artist']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \n",
    "            \"mode\", \"loudness\", \"tempo\", \"valence\", 'popularity_artist']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity_artist</th>\n",
       "      <th>popularity_song</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6.600000e+03</td>\n",
       "      <td>6600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.080152</td>\n",
       "      <td>48.516364</td>\n",
       "      <td>0.571883</td>\n",
       "      <td>0.666534</td>\n",
       "      <td>5.246818</td>\n",
       "      <td>-7.366078</td>\n",
       "      <td>0.664697</td>\n",
       "      <td>0.219285</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>0.186554</td>\n",
       "      <td>0.484610</td>\n",
       "      <td>120.547484</td>\n",
       "      <td>2.804095e+05</td>\n",
       "      <td>3.942879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.238109</td>\n",
       "      <td>19.613890</td>\n",
       "      <td>0.165417</td>\n",
       "      <td>0.219595</td>\n",
       "      <td>3.573931</td>\n",
       "      <td>4.322217</td>\n",
       "      <td>0.472132</td>\n",
       "      <td>0.276974</td>\n",
       "      <td>0.228501</td>\n",
       "      <td>0.155939</td>\n",
       "      <td>0.246824</td>\n",
       "      <td>28.266113</td>\n",
       "      <td>3.689502e+05</td>\n",
       "      <td>0.348065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-44.907000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001720e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-8.584250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>99.928750</td>\n",
       "      <td>1.975422e+05</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-6.239000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>119.974000</td>\n",
       "      <td>2.238800e+05</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-4.744000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334250</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>138.179500</td>\n",
       "      <td>2.594130e+05</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.716000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>214.419000</td>\n",
       "      <td>6.000295e+06</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity_artist  popularity_song  danceability       energy  \\\n",
       "count        6600.000000      6600.000000   6600.000000  6600.000000   \n",
       "mean           63.080152        48.516364      0.571883     0.666534   \n",
       "std            17.238109        19.613890      0.165417     0.219595   \n",
       "min             0.000000         1.000000      0.000000     0.000000   \n",
       "25%            55.000000        37.000000      0.469000     0.536000   \n",
       "50%            66.000000        51.000000      0.585000     0.712000   \n",
       "75%            75.000000        64.000000      0.689000     0.838000   \n",
       "max           100.000000        88.000000      0.980000     1.000000   \n",
       "\n",
       "               key     loudness         mode  acousticness  instrumentalness  \\\n",
       "count  6600.000000  6600.000000  6600.000000   6600.000000       6600.000000   \n",
       "mean      5.246818    -7.366078     0.664697      0.219285          0.083560   \n",
       "std       3.573931     4.322217     0.472132      0.276974          0.228501   \n",
       "min       0.000000   -44.907000     0.000000      0.000000          0.000000   \n",
       "25%       2.000000    -8.584250     0.000000      0.013400          0.000000   \n",
       "50%       5.000000    -6.239000     1.000000      0.083900          0.000014   \n",
       "75%       9.000000    -4.744000     1.000000      0.334250          0.003775   \n",
       "max      11.000000    -0.716000     1.000000      0.995000          0.999000   \n",
       "\n",
       "          liveness      valence        tempo   duration_ms  time_signature  \n",
       "count  6600.000000  6600.000000  6600.000000  6.600000e+03     6600.000000  \n",
       "mean      0.186554     0.484610   120.547484  2.804095e+05        3.942879  \n",
       "std       0.155939     0.246824    28.266113  3.689502e+05        0.348065  \n",
       "min       0.000000     0.000000     0.000000  1.001720e+05        0.000000  \n",
       "25%       0.093600     0.289000    99.928750  1.975422e+05        4.000000  \n",
       "50%       0.123000     0.481000   119.974000  2.238800e+05        4.000000  \n",
       "75%       0.229000     0.677000   138.179500  2.594130e+05        4.000000  \n",
       "max       0.981000     0.981000   214.419000  6.000295e+06        5.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign 1 to all songs with a popularity of > 57 and 0 to all songs with a popularity of <= 57\n",
    "df_nn['popularity_song'] = df_nn['popularity_song'].apply(lambda x: 1 if x > 57 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4108"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of songs with popularity of 0\n",
    "df_nn.loc[df_nn['popularity_song'] == 0, 'popularity_song'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2492"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of songs with popularity of 1\n",
    "df_nn.loc[df_nn['popularity_song'] == 1, 'popularity_song'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity_artist</th>\n",
       "      <th>popularity_song</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6.600000e+03</td>\n",
       "      <td>6600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.080152</td>\n",
       "      <td>0.377576</td>\n",
       "      <td>0.571883</td>\n",
       "      <td>0.666534</td>\n",
       "      <td>5.246818</td>\n",
       "      <td>-7.366078</td>\n",
       "      <td>0.664697</td>\n",
       "      <td>0.219285</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>0.186554</td>\n",
       "      <td>0.484610</td>\n",
       "      <td>120.547484</td>\n",
       "      <td>2.804095e+05</td>\n",
       "      <td>3.942879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.238109</td>\n",
       "      <td>0.484817</td>\n",
       "      <td>0.165417</td>\n",
       "      <td>0.219595</td>\n",
       "      <td>3.573931</td>\n",
       "      <td>4.322217</td>\n",
       "      <td>0.472132</td>\n",
       "      <td>0.276974</td>\n",
       "      <td>0.228501</td>\n",
       "      <td>0.155939</td>\n",
       "      <td>0.246824</td>\n",
       "      <td>28.266113</td>\n",
       "      <td>3.689502e+05</td>\n",
       "      <td>0.348065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-44.907000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.001720e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-8.584250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>99.928750</td>\n",
       "      <td>1.975422e+05</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-6.239000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>119.974000</td>\n",
       "      <td>2.238800e+05</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-4.744000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334250</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>138.179500</td>\n",
       "      <td>2.594130e+05</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-0.716000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>214.419000</td>\n",
       "      <td>6.000295e+06</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       popularity_artist  popularity_song  danceability       energy  \\\n",
       "count        6600.000000      6600.000000   6600.000000  6600.000000   \n",
       "mean           63.080152         0.377576      0.571883     0.666534   \n",
       "std            17.238109         0.484817      0.165417     0.219595   \n",
       "min             0.000000         0.000000      0.000000     0.000000   \n",
       "25%            55.000000         0.000000      0.469000     0.536000   \n",
       "50%            66.000000         0.000000      0.585000     0.712000   \n",
       "75%            75.000000         1.000000      0.689000     0.838000   \n",
       "max           100.000000         1.000000      0.980000     1.000000   \n",
       "\n",
       "               key     loudness         mode  acousticness  instrumentalness  \\\n",
       "count  6600.000000  6600.000000  6600.000000   6600.000000       6600.000000   \n",
       "mean      5.246818    -7.366078     0.664697      0.219285          0.083560   \n",
       "std       3.573931     4.322217     0.472132      0.276974          0.228501   \n",
       "min       0.000000   -44.907000     0.000000      0.000000          0.000000   \n",
       "25%       2.000000    -8.584250     0.000000      0.013400          0.000000   \n",
       "50%       5.000000    -6.239000     1.000000      0.083900          0.000014   \n",
       "75%       9.000000    -4.744000     1.000000      0.334250          0.003775   \n",
       "max      11.000000    -0.716000     1.000000      0.995000          0.999000   \n",
       "\n",
       "          liveness      valence        tempo   duration_ms  time_signature  \n",
       "count  6600.000000  6600.000000  6600.000000  6.600000e+03     6600.000000  \n",
       "mean      0.186554     0.484610   120.547484  2.804095e+05        3.942879  \n",
       "std       0.155939     0.246824    28.266113  3.689502e+05        0.348065  \n",
       "min       0.000000     0.000000     0.000000  1.001720e+05        0.000000  \n",
       "25%       0.093600     0.289000    99.928750  1.975422e+05        4.000000  \n",
       "50%       0.123000     0.481000   119.974000  2.238800e+05        4.000000  \n",
       "75%       0.229000     0.677000   138.179500  2.594130e+05        4.000000  \n",
       "max       0.981000     0.981000   214.419000  6.000295e+06        5.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nn.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the X and y sets\n",
    "X = df_nn[features]\n",
    "y = df_nn['popularity_song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_val)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 200 200\n"
     ]
    }
   ],
   "source": [
    "number_input_features = X_train.shape[1]\n",
    "hidden_nodes_layer1 = 200\n",
    "hidden_nodes_layer2 = 200\n",
    "\n",
    "\n",
    "print(number_input_features, hidden_nodes_layer1, hidden_nodes_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 14:09:26.989745: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(\n",
    "    Dense(units=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Layer 2\n",
    "model.add(Dense(units=hidden_nodes_layer1, activation=\"relu\"))\n",
    "\n",
    "# Layer 3 \n",
    "model.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1 , activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 2s 8ms/step - loss: 0.6066 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5532 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5429 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5300 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5342 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5319 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5337 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5299 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5237 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5283 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5342 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5270 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5295 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5325 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5280 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5413 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5288 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5427 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5426 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5364 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5403 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5402 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5465 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5468 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5407 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5485 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5424 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5512 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5537 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5555 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5650 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5623 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5646 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5641 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5728 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5509 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5757 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5682 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5904 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5655 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5713 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5807 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6010 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5854 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5854 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5909 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6007 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5924 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5867 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.5923 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6054 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6149 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6217 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6113 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6179 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6139 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6478 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6468 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6346 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6505 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6616 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6543 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6400 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6622 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6741 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6685 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6653 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6909 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7052 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6984 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7156 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6980 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7098 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7185 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7251 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7625 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7351 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7368 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7357 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7381 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7573 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7661 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7686 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7870 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7949 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8110 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8371 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7970 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8207 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8154 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8340 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8455 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8419 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8296 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8721 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8626 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8725 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.9267 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.9143 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.3669 - tp: 1362.0000 - tn: 0.0000e+00 - fp: 2350.0000 - fn: 0.0000e+00 - precision: 0.3669 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8723 - val_accuracy: 0.3780 - val_tp: 468.0000 - val_tn: 0.0000e+00 - val_fp: 770.0000 - val_fn: 0.0000e+00 - val_precision: 0.3780 - val_recall: 1.0000 - val_auc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "training_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               2200      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,711\n",
      "Trainable params: 42,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Loss'}, xlabel='Epoch'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting loss\n",
    "loss_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Epoch\": range(1, epochs + 1),\n",
    "        \"Train\": training_history.history[\"loss\"],\n",
    "        \"Val\": training_history.history[\"val_loss\"],\n",
    "    }\n",
    ")\n",
    "loss_df.set_index(\"Epoch\", inplace=True)\n",
    "loss_df.plot(title=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Accuracy'}, xlabel='Epoch'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting accuracy\n",
    "accuracy_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Epoch\": range(1, epochs + 1),\n",
    "        \"Train\": training_history.history[\"accuracy\"],\n",
    "        \"Val\": training_history.history[\"val_accuracy\"],\n",
    "    }\n",
    ")\n",
    "accuracy_df.set_index(\"Epoch\", inplace=True)\n",
    "accuracy_df.plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'AUC'}, xlabel='Epoch'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting AUC\n",
    "auc_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Epoch\": range(1, epochs + 1),\n",
    "        \"Train\": training_history.history[\"auc\"],\n",
    "        \"Val\": training_history.history[\"val_auc\"],\n",
    "    }\n",
    ")\n",
    "auc_df.set_index(\"Epoch\", inplace=True)\n",
    "auc_df.plot(title=\"AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 14.658145904541016,\n",
       " 'accuracy': 0.4012121260166168,\n",
       " 'tp': 662.0,\n",
       " 'tn': 0.0,\n",
       " 'fp': 988.0,\n",
       " 'fn': 0.0,\n",
       " 'precision': 0.4012121260166168,\n",
       " 'recall': 1.0,\n",
       " 'auc': 0.5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Define metrics dictionary\n",
    "metrics = {k: v for k, v in zip(model.metrics_names, scores)}\n",
    "\n",
    "# Display evaluation metrics results\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Positive (1)</th>\n",
       "      <th>Negative (0)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive(1)</th>\n",
       "      <td>TP=662.0</td>\n",
       "      <td>FN=988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative(0)</th>\n",
       "      <td>FP=0.0</td>\n",
       "      <td>TN=0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   Positive (1) Negative (0)\n",
       "Actual                               \n",
       "Positive(1)     TP=662.0     FN=988.0\n",
       "Negative(0)       FP=0.0       TN=0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the confusion matrix data\n",
    "cm_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive (1)\": [f\"TP={metrics['tp']}\", f\"FP={metrics['fn']}\"],\n",
    "        \"Negative (0)\": [f\"FN={metrics['fp']}\", f\"TN={metrics['tn']}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_df.index.name = \"Actual\"\n",
    "cm_df.columns.name = \"Predicted\"\n",
    "\n",
    "# Show the confusion matrix\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.40      0.57      1650\n",
      "\n",
      "    accuracy                           0.40      1650\n",
      "   macro avg       0.50      0.20      0.29      1650\n",
      "weighted avg       1.00      0.40      0.57      1650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AndrewArgyrou/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/AndrewArgyrou/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/AndrewArgyrou/opt/anaconda3/envs/dev/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import the classification_report method from sklearn\n",
    "\n",
    "# Predict classes using testing data\n",
    "y_predict_classes = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_predict_classes, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn_model = KNeighborsClassifier() \n",
    "knn_model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, knn_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neig = np.arange(1, 25)\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for i, k in enumerate(neig):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_accuracy.append(knn.score(X_train, y_train))\n",
    "    test_accuracy.append(knn.score(X_test, y_test))\n",
    "\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.plot(neig, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neig, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Knn k value VS Accuracy')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(neig)\n",
    "plt.savefig('graph.png')\n",
    "plt.show()\n",
    "print(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35bec98dce1b3b28cda1817078865e650a01d463cb657688225eeec36a1d3f02"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
